{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# get the file names in each directory\n",
    "train_neg = [f for f in os.listdir('aclImdb/train/neg')]\n",
    "train_pos = [f for f in os.listdir('aclImdb/train/pos')]\n",
    "test_neg = [f for f in os.listdir('aclImdb/test/neg')]\n",
    "test_pos = [f for f in os.listdir('aclImdb/test/pos')]\n",
    "\n",
    "def read(directory,path):\n",
    "    texts = []\n",
    "    for f in directory:\n",
    "        f=os.path.join(path,f)\n",
    "        with open(f, \"rt\") as inp_file:\n",
    "            text = inp_file.readlines()\n",
    "            assert len(text)==1\n",
    "            texts.append(text[0].strip())\n",
    "    return texts\n",
    "\n",
    "# read all the files in each directory into a list\n",
    "train_neg = read(train_neg,'aclImdb/train/neg')\n",
    "train_pos = read(train_pos,'aclImdb/train/pos')\n",
    "test_neg = read(test_neg,'aclImdb/test/neg')\n",
    "test_pos = read(test_pos,'aclImdb/test/pos')\n",
    "\n",
    "# add labels for texts\n",
    "train_neg = [(text,-1) for text in train_neg]\n",
    "train_pos = [(text,1) for text in train_pos]\n",
    "test_neg = [(text,-1) for text in test_neg]\n",
    "test_pos = [(text,1) for text in test_pos]\n",
    "\n",
    "# shuffle the training set\n",
    "random.shuffle(train_neg + train_pos)\n",
    "\n",
    "train_texts = [text for text, label in train]\n",
    "train_labels = [label for text, label in train]\n",
    "#print(train_texts[:3])\n",
    "print(train_labels[:20])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from eli5 import show_weights\n",
    "\n",
    "space_tokenizer = lambda text: text.split()\n",
    "\n",
    "\n",
    "# Featurization and vectorization\n",
    "vectorizer = TfidfVectorizer(tokenizer=space_tokenizer, ngram_range=(1,2))\n",
    "vectorizer.fit(train_texts)\n",
    "\n",
    "train_X = vectorizer.transform(train_texts)\n",
    "devel_X = vectorizer.transform(devel_texts)\n",
    "test_X = vectorizer.transform(test_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 12s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Training and prediction\n",
    "\n",
    "\n",
    "%%time\n",
    "classifier = LinearSVC(\n",
    "    C=1.0,\n",
    "    class_weight=None,\n",
    "    max_iter=1000,\n",
    "    loss='squared_hinge'\n",
    ")\n",
    "classifier.fit(train_X, train_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])\n",
      " list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_Y = classifier.predict(devel_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation and analysis\n",
    "accuracy = accuracy_score(devel_Y, pred_Y)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(devel_Y, pred_Y, labels=['spam', 'ham']).ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print('accuracy {:.2%}'.format(accuracy))\n",
    "print('precision {:.2%}, recall {:.2%}, f-score {:.2%}'.format(precision, recall, f_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_weights(classifier, vec=vectorizer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
